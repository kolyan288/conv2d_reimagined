{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –°–ø–∞—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ Conv2D: Original vs Custom —Å –∞–Ω–∞–ª–∏–∑–æ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "\n",
    "Notebook –¥–ª—è —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å–ø–∞—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ Conv2D –∏ –∫–∞—Å—Ç–æ–º–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Img2Col —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏.\n",
    "\n",
    "**–ú–µ—Ç–æ–¥—ã —Å–ø–∞—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:**\n",
    "- MagnitudePruner (—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–∞—è –∏ –Ω–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–∞—è)\n",
    "- IterativePruner (—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–∞—è –∏ –Ω–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–∞—è)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip uninstall torch torchvision torchaudio -y\n",
    "# pip cache purge\n",
    "# pip install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cu130"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch –≤–µ—Ä—Å–∏—è: 2.10.0.dev20251118+cu130\n",
      "True\n",
      "NVIDIA GeForce RTX 5080\n",
      "(12, 0)\n",
      "–ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f'PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}')\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.get_device_capability(0))\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'–ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. –ò–º–ø–æ—Ä—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\n"
     ]
    }
   ],
   "source": [
    "project_root = Path(os.getcwd()).parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "sys.path.insert(0, str(project_root / 'experiments'))\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "\n",
    "from src.models.camvid_segmentation_multiclass import (\n",
    "    get_dataloaders,\n",
    "    CamVidModel,\n",
    "    visualize_sample,\n",
    "    visualize_data,\n",
    "    train_val,\n",
    "    save_load_torch_model,\n",
    ")\n",
    "\n",
    "from experiments.common.replace_conv_resnet import replace_conv2d_with_custom\n",
    "\n",
    "from experiments.prune import MagnitudePruner, IterativePruner\n",
    "\n",
    "from src.core.latency import (\n",
    "    latency_cpu,\n",
    "    latency_gpu,\n",
    "    latency_cpu_profiler,\n",
    "    latency_gpu_event,\n",
    ")\n",
    "\n",
    "from src.utils import (\n",
    "    basicconv_model,\n",
    "    custom_conv_model,\n",
    "    compare_models,\n",
    "    analyze_benchmark_data,\n",
    ")\n",
    "\n",
    "from src.core.metric_writer import LatencyMetricsWriter\n",
    "\n",
    "print('–í—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'train.txt', 'trainannot', 'testannot', 'valannot', 'val', 'val.txt', 'test', 'test.txt']\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = os.getcwd()\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, 'data', 'CamVid')\n",
    "\n",
    "x_train_dir = os.path.join(DATA_DIR, \"train\")\n",
    "y_train_dir = os.path.join(DATA_DIR, \"trainannot\")\n",
    "x_valid_dir = os.path.join(DATA_DIR, \"val\")\n",
    "y_valid_dir = os.path.join(DATA_DIR, \"valannot\")\n",
    "x_test_dir = os.path.join(DATA_DIR, \"test\")\n",
    "y_test_dir = os.path.join(DATA_DIR, \"testannot\")\n",
    "\n",
    "print(os.listdir(DATA_DIR))\n",
    "\n",
    "WEIGHTS_DIR = 'weights'\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True)\n",
    "\n",
    "ORIGINAL_MODEL_PATH = os.path.join(WEIGHTS_DIR, 'originalConv_camvid_model_fp32.pt')\n",
    "CUSTOM_MODEL_PATH = os.path.join(WEIGHTS_DIR, 'replacedConv_camvid_model_fp32.pt')\n",
    "\n",
    "config = {\n",
    "    'batch_size': 8,\n",
    "}\n",
    "\n",
    "pruning_configs = [\n",
    "    # {'method': 'MagnitudePruner', 'sparsity': 0.5, 'structured': False, 'epochs': 5},\n",
    "    # {'method': 'MagnitudePruner', 'sparsity': 0.5, 'structured': True, 'epochs': 5},\n",
    "    # {'method': 'IterativePruner', 'sparsity': 0.5, 'structured': False, 'epochs': 5},\n",
    "    {'method': 'IterativePruner', 'sparsity': 0.5, 'structured': True, 'epochs': 8},\n",
    "]\n",
    "\n",
    "bs_range = [1, 2, 4, 8, 16, 32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç CamVid...\n",
      "–î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω\n"
     ]
    }
   ],
   "source": [
    "print('–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç CamVid...')\n",
    "\n",
    "try:\n",
    "    train_loader, valid_loader, test_loader = get_dataloaders(\n",
    "        x_train_dir, y_train_dir, x_valid_dir, y_valid_dir, x_test_dir, y_test_dir, bs=config['batch_size']\n",
    "    )\n",
    "    print(f'–î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω')\n",
    "except Exception as e:\n",
    "    print(f'–û—à–∏–±–∫–∞: {e}')\n",
    "    train_loader = []\n",
    "    valid_loader = []\n",
    "    test_loader = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏...\n",
      "Original –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞\n",
      "Custom –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞\n",
      "–û–±–µ –º–æ–¥–µ–ª–∏ –≥–æ—Ç–æ–≤—ã\n"
     ]
    }
   ],
   "source": [
    "print('–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏...')\n",
    "\n",
    "OUT_CLASSES = len(train_loader.dataset.CLASSES)\n",
    "original_model = CamVidModel(\"FPN\", \"resnext50_32x4d\", in_channels=3, out_classes=OUT_CLASSES).to(DEVICE)\n",
    "if os.path.exists(ORIGINAL_MODEL_PATH):\n",
    "    original_model.load_state_dict(torch.load(ORIGINAL_MODEL_PATH, map_location=DEVICE))\n",
    "    print(f'Original –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞')\n",
    "else:\n",
    "    print(f'Original –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞')\n",
    "\n",
    "original_model.eval()\n",
    "\n",
    "custom_model = CamVidModel(\"FPN\", \"resnext50_32x4d\", in_channels=3, out_classes=OUT_CLASSES).to(DEVICE)\n",
    "replace_conv2d_with_custom(custom_model)\n",
    "if os.path.exists(CUSTOM_MODEL_PATH):\n",
    "    custom_model.load_state_dict(torch.load(CUSTOM_MODEL_PATH, map_location=DEVICE))\n",
    "    print(f'Custom –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞')\n",
    "else:\n",
    "    print(f'Custom –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞')\n",
    "\n",
    "custom_model.eval()\n",
    "print(f'–û–±–µ –º–æ–¥–µ–ª–∏ –≥–æ—Ç–æ–≤—ã')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. –°–ø–∞—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏ Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type     | Params | Mode \n",
      "---------------------------------------------\n",
      "0 | model   | FPN      | 25.6 M | train\n",
      "1 | loss_fn | DiceLoss | 0      | train\n",
      "---------------------------------------------\n",
      "25.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "25.6 M    Total params\n",
      "102.357   Total estimated model params size (MB)\n",
      "210       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "–°–ü–ê–†–°–ò–§–ò–ö–ê–¶–ò–Ø –ò FINE-TUNING\n",
      "================================================================================\n",
      "\n",
      "–ú–µ—Ç–æ–¥: IterativePruner (structured)\n",
      "Original Conv2d:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191172f8c56f49d5b1fdd74b7a3b2b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7c2b25b09b44eb90afc796cd9a70a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning step applied at epoch 0 start. Current sparsity: 0.1000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748c82fd220d448db6843814aaf76987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning step applied at epoch 1 start. Current sparsity: 0.1000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be2efd13e2f84f4d8a1c668fe36d81f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning step applied at epoch 2 start. Current sparsity: 0.1000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3be4b6b7db045e9ac8a8042dfd6b69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning step applied at epoch 3 start. Current sparsity: 0.3000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e818f16c9ce415885aba6ae612f6c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning step applied at epoch 4 start. Current sparsity: 0.3000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c70c33ffd7342468b888348ad43f5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning step applied at epoch 5 start. Current sparsity: 0.3000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf81a01438a4464b0fbff52bf307774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning step applied at epoch 6 start. Current sparsity: 0.5000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e8750c6dd54712ac8863a7b35ffe91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning step applied at epoch 7 start. Current sparsity: 0.5000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a67329bd474013ad857b61cdd677fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=8` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ffd772540074b1f8a55dbe55043c30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'valid_per_image_iou': 0.7003498077392578, 'valid_dataset_iou': 0.6993597745895386}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af109e4fbaa4c5fbb15d3bd548abad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                                    ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'test_per_image_iou': 0.6463389992713928, 'test_dataset_iou': 0.6417989134788513}]\n",
      "  –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: weights/originalConv_iterative_structured_camvid_model_sp05_fp32.pt\n",
      "Custom Img2Col:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type     | Params | Mode \n",
      "---------------------------------------------\n",
      "0 | model   | FPN      | 25.6 M | train\n",
      "1 | loss_fn | DiceLoss | 0      | train\n",
      "---------------------------------------------\n",
      "25.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "25.6 M    Total params\n",
      "102.357   Total estimated model params size (MB)\n",
      "210       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb2bd40e24d45a1acb2b9770d47c7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e7ca03e51c4df29f33b9c17c874e8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning step applied at epoch 0 start. Current sparsity: 0.1000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c2430866da4b02bfea3ffa4291f6b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning step applied at epoch 1 start. Current sparsity: 0.1000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23012ba1e8c54668a2718c08c7b87ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning step applied at epoch 2 start. Current sparsity: 0.1000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfca41546eed4ca78d4e97dca28644ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning step applied at epoch 3 start. Current sparsity: 0.3000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4465f3de18f240e9bbd17ed544262e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning step applied at epoch 4 start. Current sparsity: 0.3000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7090c43edc496dbdc739d3064eb81c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning step applied at epoch 5 start. Current sparsity: 0.3000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec45d0cf0134a47a11a34c57aad60f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning step applied at epoch 6 start. Current sparsity: 0.5000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5700b9ac16f44dcc9550c08357f90de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning step applied at epoch 7 start. Current sparsity: 0.5000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d55c1d7ca747c1a62f74dd7d4f2525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=8` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7addaeff2474b3fa93800e48fca6134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'valid_per_image_iou': 0.5965787768363953, 'valid_dataset_iou': 0.5960158705711365}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f902c9afcf244feaec42f21168f1e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                                    ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'test_per_image_iou': 0.5163288116455078, 'test_dataset_iou': 0.5135128498077393}]\n",
      "  –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: weights/replacedConv_iterative_structured_camvid_model_sp05_fp32.pt\n",
      "\n",
      "‚úì –°–ø–∞—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ú–æ–¥–µ–ª–µ–π: 2\n"
     ]
    }
   ],
   "source": [
    "pruned_models = {}\n",
    "\n",
    "print('='*80)\n",
    "print('–°–ü–ê–†–°–ò–§–ò–ö–ê–¶–ò–Ø –ò FINE-TUNING')\n",
    "print('='*80)\n",
    "\n",
    "for config_idx, pruning_config in enumerate(pruning_configs):\n",
    "    method = pruning_config['method']\n",
    "    sparsity = pruning_config['sparsity']\n",
    "    structured = pruning_config['structured']\n",
    "    epochs = pruning_config['epochs']\n",
    "    \n",
    "    struct_str = 'structured' if structured else 'unstructured'\n",
    "    method_str = method.replace('Pruner', '').lower()\n",
    "    \n",
    "    print(f'\\n–ú–µ—Ç–æ–¥: {method} ({struct_str})')\n",
    "    \n",
    "    # Original –º–æ–¥–µ–ª—å\n",
    "    print(f'Original Conv2d:')\n",
    "    \n",
    "    if method == 'MagnitudePruner':\n",
    "        pruner = MagnitudePruner(sparsity=sparsity, structured=structured)\n",
    "        orig_model = CamVidModel(\"FPN\", \"resnext50_32x4d\", in_channels=3, out_classes=OUT_CLASSES).to(DEVICE)\n",
    "        orig_model.load_state_dict(original_model.state_dict())\n",
    "        orig_model.train()\n",
    "        orig_model = pruner.apply_pruning(orig_model)\n",
    "    else:\n",
    "        pruner = IterativePruner(\n",
    "            initial_sparsity=0.1,\n",
    "            final_sparsity=sparsity,\n",
    "            num_iterations=epochs,\n",
    "            epochs_per_iteration=3,\n",
    "            structured=structured\n",
    "        )\n",
    "        orig_model = CamVidModel(\"FPN\", \"resnext50_32x4d\", in_channels=3, out_classes=OUT_CLASSES, iterative_pruner=pruner).to(DEVICE)\n",
    "        orig_model.load_state_dict(original_model.state_dict())\n",
    "        orig_model.train()\n",
    "    \n",
    "    if len(train_loader) > 0:\n",
    "        valid_metrics, test_metrics, _ = train_val(\n",
    "            orig_model,\n",
    "            train_loader,\n",
    "            valid_loader,\n",
    "            test_loader,\n",
    "            max_epochs=epochs,\n",
    "            test=True,\n",
    "        )\n",
    "    else:\n",
    "        valid_metrics = [{'valid_dataset_iou': None}]\n",
    "        test_metrics = [{'test_dataset_iou': None}]\n",
    "    \n",
    "    orig_model.eval()\n",
    "    orig_save_path = os.path.join(\n",
    "        WEIGHTS_DIR,\n",
    "        f'originalConv_{method_str}_{struct_str}_camvid_model_sp0{round(sparsity*10)}_fp32.pt'\n",
    "    )\n",
    "    save_load_torch_model(orig_model, orig_save_path, save=True)\n",
    "    print(f'  –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {orig_save_path}')\n",
    "    pruned_models[f'{method_str}_{struct_str}_sp0{round(sparsity*10)}'] = (orig_model, valid_metrics, test_metrics)\n",
    "\n",
    "    # Custom –º–æ–¥–µ–ª—å\n",
    "    print(f'Custom Img2Col:')\n",
    "    \n",
    "    if method == 'MagnitudePruner':\n",
    "        pruner = MagnitudePruner(sparsity=sparsity, structured=structured)\n",
    "        cust_model = CamVidModel(\"FPN\", \"resnext50_32x4d\", in_channels=3, out_classes=OUT_CLASSES).to(DEVICE)\n",
    "        replace_conv2d_with_custom(cust_model)\n",
    "        cust_model.load_state_dict(custom_model.state_dict())\n",
    "        cust_model.train()\n",
    "        cust_model = pruner.apply_pruning(cust_model)\n",
    "    else:\n",
    "        pruner = IterativePruner(\n",
    "            initial_sparsity=0.1,\n",
    "            final_sparsity=sparsity,\n",
    "            num_iterations=epochs,\n",
    "            epochs_per_iteration=3,\n",
    "            structured=structured\n",
    "        )\n",
    "        cust_model = CamVidModel(\"FPN\", \"resnext50_32x4d\", in_channels=3, out_classes=OUT_CLASSES, iterative_pruner=pruner).to(DEVICE)\n",
    "        replace_conv2d_with_custom(cust_model)\n",
    "        cust_model.load_state_dict(custom_model.state_dict())\n",
    "        cust_model.train()\n",
    "    \n",
    "    if len(train_loader) > 0:\n",
    "        valid_metrics, test_metrics, _ = train_val(\n",
    "            cust_model,\n",
    "            train_loader,\n",
    "            valid_loader,\n",
    "            test_loader,\n",
    "            max_epochs=epochs,\n",
    "            test=True,\n",
    "        )\n",
    "    else:\n",
    "        valid_metrics = [{'valid_dataset_iou': None}]\n",
    "        test_metrics = [{'test_dataset_iou': None}]\n",
    "    \n",
    "    cust_model.eval()\n",
    "    cust_save_path = os.path.join(\n",
    "        WEIGHTS_DIR,\n",
    "        f'replacedConv_{method_str}_{struct_str}_camvid_model_sp0{round(sparsity*10)}_fp32.pt'\n",
    "    )\n",
    "    save_load_torch_model(cust_model, cust_save_path, save=True)\n",
    "    print(f'  –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {cust_save_path}')\n",
    "    pruned_models[f'ReplacedConv_{method_str}_{struct_str}_sp0{round(sparsity*10)}'] = (cust_model, valid_metrics, test_metrics)\n",
    "\n",
    "print(f'\\n‚úì –°–ø–∞—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ú–æ–¥–µ–ª–µ–π: {len(pruned_models)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['iterative_structured_sp05', 'ReplacedConv_iterative_structured_sp05'])\n"
     ]
    }
   ],
   "source": [
    "print(pruned_models.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_benchmark = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model_name, (model, valid_metrics, test_metrics) in pruned_models.items():\n",
    "#     models_to_benchmark.append((model_name, model, valid_metrics, test_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74cdb1b545854d04bc512ccb3aff60e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'valid_per_image_iou': 0.849943995475769, 'valid_dataset_iou': 0.849575936794281}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b569c22c08dd442c92c6e2de7ac19441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                                    ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'test_per_image_iou': 0.784477174282074, 'test_dataset_iou': 0.7822542190551758}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcaaee8f0afd46e4b2dc73b04aaeb487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'valid_per_image_iou': 0.5913414359092712, 'valid_dataset_iou': 0.5902272462844849}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e1195bf3f44dbfb0b6e0c99c385744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                                    ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'test_per_image_iou': 0.548675000667572, 'test_dataset_iou': 0.5446076989173889}]\n"
     ]
    }
   ],
   "source": [
    "print('–ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏...')\n",
    "\n",
    "valid_metrics, test_metrics, _ = train_val(\n",
    "    original_model,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    test_loader,\n",
    "    max_epochs=5,\n",
    "    train=False,\n",
    "    test=True,\n",
    ")\n",
    "\n",
    "models_to_benchmark.append(('original_baseline', original_model, valid_metrics, test_metrics))\n",
    "\n",
    "valid_metrics, test_metrics, _ = train_val(\n",
    "    custom_model,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    test_loader,\n",
    "    max_epochs=5,\n",
    "    train=False,\n",
    "    test=True,\n",
    ")\n",
    "\n",
    "models_to_benchmark.append(('ReplacedConv_baseline', custom_model, valid_metrics, test_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–≥—Ä—É–∂–∞–µ–º –µ—â–µ –º–æ–¥–µ–ª–∏...\n",
      "Original –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f529b789aa4abcbddd5d69958d9723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'valid_per_image_iou': 0.849943995475769, 'valid_dataset_iou': 0.849575936794281}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6147cc76ab4c4745831b731d620580ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                                    ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'test_per_image_iou': 0.784477174282074, 'test_dataset_iou': 0.7822542190551758}]\n"
     ]
    }
   ],
   "source": [
    "print('–ó–∞–≥—Ä—É–∂–∞–µ–º –µ—â–µ –º–æ–¥–µ–ª–∏...')\n",
    "\n",
    "more_model = CamVidModel(\"FPN\", \"resnext50_32x4d\", in_channels=3, out_classes=OUT_CLASSES).to(DEVICE)\n",
    "\n",
    "MORE_MODEL_PATH = os.path.join(WEIGHTS_DIR, 'originalConv_iterative_structured_camvid_model_sp05_fp32.pt')\n",
    "if os.path.exists(MORE_MODEL_PATH):\n",
    "    more_model.load_state_dict(torch.load(ORIGINAL_MODEL_PATH, map_location=DEVICE))\n",
    "    print(f'Original –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞')\n",
    "else:\n",
    "    print(f'Original –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞')\n",
    "\n",
    "original_model.eval()\n",
    "\n",
    "valid_metrics, test_metrics, _ = train_val(\n",
    "    more_model,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    test_loader,\n",
    "    max_epochs=5,\n",
    "    train=False,\n",
    "    test=True,\n",
    ")\n",
    "\n",
    "models_to_benchmark.append(('iterative_structured_camvid_model_sp05_fp32', more_model, valid_metrics, test_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006aaa2df77d4e21a722a840d388c3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'valid_per_image_iou': 0.5965787768363953, 'valid_dataset_iou': 0.5960158705711365}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252f058fad924577a6289d792c9c00f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                                    ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'test_per_image_iou': 0.5163288116455078, 'test_dataset_iou': 0.5135128498077393}]\n"
     ]
    }
   ],
   "source": [
    "more_model = CamVidModel(\"FPN\", \"resnext50_32x4d\", in_channels=3, out_classes=OUT_CLASSES).to(DEVICE)\n",
    "replace_conv2d_with_custom(more_model)\n",
    "\n",
    "MORE_MODEL_PATH = os.path.join(WEIGHTS_DIR, 'replacedConv_iterative_structured_camvid_model_sp05_fp32.pt')\n",
    "if os.path.exists(MORE_MODEL_PATH):\n",
    "    more_model.load_state_dict(torch.load(MORE_MODEL_PATH, map_location=DEVICE))\n",
    "    print(f'Custom –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞')\n",
    "else:\n",
    "    print(f'Custom –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞')\n",
    "\n",
    "custom_model.eval()\n",
    "\n",
    "valid_metrics, test_metrics, _ = train_val(\n",
    "    more_model,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    test_loader,\n",
    "    max_epochs=5,\n",
    "    train=False,\n",
    "    test=True,\n",
    ")\n",
    "\n",
    "models_to_benchmark.append(('ReplacedConv_iterative_structured_camvid_model_sp05_fp32', more_model, valid_metrics, test_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. –ë–µ–Ω—á–º–∞—Ä–∫–∏–Ω–≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–ë–µ–Ω—á–º–∞—Ä–∫–∏–Ω–≥: original_baseline\n",
      "Metrics recorded for original_baseline (batch_size=1)\n",
      "  BS=1: 2.47ms ¬± 0.01ms | 405.3 samples/s\n",
      "Metrics recorded for original_baseline (batch_size=2)\n",
      "  BS=2: 2.72ms ¬± 0.02ms | 734.9 samples/s\n",
      "Metrics recorded for original_baseline (batch_size=4)\n",
      "  BS=4: 3.10ms ¬± 0.10ms | 1288.3 samples/s\n",
      "Metrics recorded for original_baseline (batch_size=8)\n",
      "  BS=8: 4.68ms ¬± 0.09ms | 1708.7 samples/s\n",
      "Metrics recorded for original_baseline (batch_size=16)\n",
      "  BS=16: 7.05ms ¬± 0.25ms | 2268.3 samples/s\n",
      "Metrics recorded for original_baseline (batch_size=32)\n",
      "  BS=32: 11.56ms ¬± 0.01ms | 2767.9 samples/s\n",
      "\n",
      "–ë–µ–Ω—á–º–∞—Ä–∫–∏–Ω–≥: ReplacedConv_baseline\n",
      "Metrics recorded for ReplacedConv_baseline (batch_size=1)\n",
      "  BS=1: 13.23ms ¬± 0.05ms | 75.6 samples/s\n",
      "Metrics recorded for ReplacedConv_baseline (batch_size=2)\n",
      "  BS=2: 13.54ms ¬± 0.08ms | 147.7 samples/s\n",
      "Metrics recorded for ReplacedConv_baseline (batch_size=4)\n",
      "  BS=4: 13.57ms ¬± 0.11ms | 294.8 samples/s\n"
     ]
    }
   ],
   "source": [
    "WARM_N = 5\n",
    "BENCH_N = 50\n",
    "\n",
    "csv_filename = 'pruning_benchmark_results.csv'\n",
    "writer = LatencyMetricsWriter(csv_filename)\n",
    "\n",
    "benchmark_results = {}\n",
    "\n",
    "for model_name, model, valid_metrics, test_metrics in models_to_benchmark:\n",
    "    print(f'\\n–ë–µ–Ω—á–º–∞—Ä–∫–∏–Ω–≥: {model_name}')\n",
    "    model.eval()\n",
    "    \n",
    "    for bs in bs_range:\n",
    "        input_batch = torch.ones([bs, 3, 128, 128], dtype=torch.float32, device=DEVICE)\n",
    "        \n",
    "        cpu_profiler = latency_cpu_profiler(\n",
    "            model,\n",
    "            input_batch,\n",
    "            warmup_n=WARM_N,\n",
    "            benchmark_n=BENCH_N\n",
    "        )\n",
    "        \n",
    "        if DEVICE.type == 'cuda':\n",
    "            gpu_mean, gpu_std = latency_gpu_event(\n",
    "                model,\n",
    "                input_batch,\n",
    "                warmup=WARM_N,\n",
    "                repeat=BENCH_N\n",
    "            )\n",
    "        else:\n",
    "            gpu_mean, gpu_std = latency_cpu(\n",
    "                model,\n",
    "                input_batch,\n",
    "                warmup_n=WARM_N,\n",
    "                benchmark_n=BENCH_N\n",
    "            )\n",
    "        \n",
    "        throughput = bs / (gpu_mean / 1000)\n",
    "        \n",
    "        # –ó–∞–ø–∏—Å—å –º–µ—Ç—Ä–∏–∫\n",
    "        val_iou = valid_metrics[0][\"valid_dataset_iou\"]\n",
    "        test_iou = test_metrics[0][\"test_dataset_iou\"]\n",
    "\n",
    "        metrics = writer.record_metrics(\n",
    "            model=model,\n",
    "            model_name=model_name,\n",
    "            batch_size=bs,\n",
    "            precision=model_name.replace(\"ReplacedConv_\", \"\"),\n",
    "            input_shape=input_batch.shape,\n",
    "            cpu_profiler=cpu_profiler,\n",
    "            gpu_latency=(gpu_mean, gpu_std),\n",
    "            notes=f\"Pruning: {model_name}\",\n",
    "            val_iou=val_iou,\n",
    "            test_iou=test_iou,\n",
    "        )\n",
    "        \n",
    "        if model_name not in benchmark_results:\n",
    "            benchmark_results[model_name] = []\n",
    "        \n",
    "        benchmark_results[model_name].append({\n",
    "            'batch_size': bs,\n",
    "            'latency_ms': gpu_mean,\n",
    "            'throughput': throughput\n",
    "        })\n",
    "        \n",
    "        print(f'  BS={bs}: {gpu_mean:.2f}ms ¬± {gpu_std:.2f}ms | {throughput:.1f} samples/s')\n",
    "\n",
    "print(f'\\n‚úì –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {csv_filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ analyze_benchmark_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots, summary, processed_df = analyze_benchmark_data('pruning_benchmark_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
